---
title: "What is the T5 Transformer and how does it work?"
date: "2021-02-15"
categories: 
  - "buffer"
  - "deep-learning"
tags: 
  - "nlp"
  - "t5"
  - "transformer"
  - "transformers"
---

The **[Text-to-Text Transfer Transformer or T5](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)** is a type of [Transformer](https://www.machinecurve.com/index.php/2020/12/28/introduction-to-transformers-in-machine-learning/) that is capable of being trained on a variety of tasks with a uniform architecture. It was created by Google AI and was published about in the paper “[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)“. Here, we’ll take a look at T5 architecture, pretraining, finetuning — including variations and the conclusions that can be derived from them. It effectively summarizes the above linked paper.
